{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca12d25",
   "metadata": {},
   "source": [
    "# SAME FILE WITH 8- Customer churn prediction using ANN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390e9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defb4143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age   \n",
       "0             1    15634602   Hargrave          619    France  Female   42  \\\n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember   \n",
       "0          2       0.00              1          1               1  \\\n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/Churn_Modelling.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34df3b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts   \n",
       "0             619    France  Female   42       2       0.00              1  \\\n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bc70fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3230f858",
   "metadata": {},
   "outputs": [],
   "source": [
    " df1[\"Gender\"].replace({'Female': 1,'Male': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a263d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Female  Age  Tenure    Balance  NumOfProducts   \n",
       "0             619    France       1   42       2       0.00              1  \\\n",
       "1             608     Spain       1   41       1   83807.86              1   \n",
       "2             502    France       1   42       8  159660.80              3   \n",
       "3             699    France       1   39       1       0.00              2   \n",
       "4             850     Spain       1   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France       0   39       5       0.00              2   \n",
       "9996          516    France       0   35      10   57369.61              1   \n",
       "9997          709    France       1   36       7       0.00              1   \n",
       "9998          772   Germany       0   42       3   75075.31              2   \n",
       "9999          792    France       1   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.rename({\"Gender\":\"Female\"}, axis=1, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895f4367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>0.454300</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>0.497932</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore        Female           Age        Tenure        Balance   \n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000   10000.000000  \\\n",
       "mean     650.528800      0.454300     38.921800      5.012800   76485.889288   \n",
       "std       96.653299      0.497932     10.487806      2.892174   62397.405202   \n",
       "min      350.000000      0.000000     18.000000      0.000000       0.000000   \n",
       "25%      584.000000      0.000000     32.000000      3.000000       0.000000   \n",
       "50%      652.000000      0.000000     37.000000      5.000000   97198.540000   \n",
       "75%      718.000000      1.000000     44.000000      7.000000  127644.240000   \n",
       "max      850.000000      1.000000     92.000000     10.000000  250898.090000   \n",
       "\n",
       "       NumOfProducts    HasCrCard  IsActiveMember  EstimatedSalary   \n",
       "count   10000.000000  10000.00000    10000.000000     10000.000000  \\\n",
       "mean        1.530200      0.70550        0.515100    100090.239881   \n",
       "std         0.581654      0.45584        0.499797     57510.492818   \n",
       "min         1.000000      0.00000        0.000000        11.580000   \n",
       "25%         1.000000      0.00000        0.000000     51002.110000   \n",
       "50%         1.000000      1.00000        1.000000    100193.915000   \n",
       "75%         2.000000      1.00000        1.000000    149388.247500   \n",
       "max         4.000000      1.00000        1.000000    199992.480000   \n",
       "\n",
       "             Exited  \n",
       "count  10000.000000  \n",
       "mean       0.203700  \n",
       "std        0.402769  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4963ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>250898.09</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199992.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CreditScore Geography  Female  Age  Tenure    Balance  NumOfProducts   \n",
       "min          350    France       0   18       0       0.00              1  \\\n",
       "max          850     Spain       1   92      10  250898.09              4   \n",
       "\n",
       "     HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "min          0               0            11.58       0  \n",
       "max          1               1        199992.48       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.agg([\"min\", \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34bfd60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Exited.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cab1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(data=df1, columns=[\"Geography\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8db03c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Female  Age  Tenure    Balance  NumOfProducts  HasCrCard   \n",
       "0             619       1   42       2       0.00              1          1  \\\n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       0   39       5       0.00              2          1   \n",
       "9996          516       0   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       0   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany   \n",
       "0                  1        101348.88       1              False  \\\n",
       "1                  1        112542.58       0              False   \n",
       "2                  0        113931.57       1              False   \n",
       "3                  0         93826.63       0              False   \n",
       "4                  1         79084.10       0              False   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0              False   \n",
       "9996               1        101699.77       0              False   \n",
       "9997               1         42085.58       1              False   \n",
       "9998               0         92888.52       1               True   \n",
       "9999               0         38190.78       0              False   \n",
       "\n",
       "      Geography_Spain  \n",
       "0               False  \n",
       "1                True  \n",
       "2               False  \n",
       "3               False  \n",
       "4                True  \n",
       "...               ...  \n",
       "9995            False  \n",
       "9996            False  \n",
       "9997            False  \n",
       "9998            False  \n",
       "9999            False  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "983313c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Female                 int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_Germany       bool\n",
       "Geography_Spain         bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc0df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df2[[\"CreditScore\", \"Age\", \"Balance\", \"EstimatedSalary\"]] = scaler.fit_transform(df2[[\"CreditScore\", \"Age\", \"Balance\", \"EstimatedSalary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65cd867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>10</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Female       Age  Tenure   Balance  NumOfProducts   \n",
       "0           0.538       1  0.324324       2  0.000000              1  \\\n",
       "1           0.516       1  0.310811       1  0.334031              1   \n",
       "2           0.304       1  0.324324       8  0.636357              3   \n",
       "3           0.698       1  0.283784       1  0.000000              2   \n",
       "4           1.000       1  0.337838       2  0.500246              1   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842       0  0.283784       5  0.000000              2   \n",
       "9996        0.332       0  0.229730      10  0.228657              1   \n",
       "9997        0.718       1  0.243243       7  0.000000              1   \n",
       "9998        0.844       0  0.324324       3  0.299226              2   \n",
       "9999        0.884       1  0.135135       4  0.518708              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany   \n",
       "0             1               1         0.506735       1              False  \\\n",
       "1             0               1         0.562709       0              False   \n",
       "2             1               0         0.569654       1              False   \n",
       "3             0               0         0.469120       0              False   \n",
       "4             1               1         0.395400       0              False   \n",
       "...         ...             ...              ...     ...                ...   \n",
       "9995          1               0         0.481341       0              False   \n",
       "9996          1               1         0.508490       0              False   \n",
       "9997          0               1         0.210390       1              False   \n",
       "9998          1               0         0.464429       1               True   \n",
       "9999          1               0         0.190914       0              False   \n",
       "\n",
       "      Geography_Spain  \n",
       "0               False  \n",
       "1                True  \n",
       "2               False  \n",
       "3               False  \n",
       "4                True  \n",
       "...               ...  \n",
       "9995            False  \n",
       "9996            False  \n",
       "9997            False  \n",
       "9998            False  \n",
       "9999            False  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3820634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[[\"Tenure\"]] = scaler.fit_transform(df2[[\"Tenure\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b3ab98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481341</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508490</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.518708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190914</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Female       Age  Tenure   Balance  NumOfProducts   \n",
       "0           0.538       1  0.324324     0.2  0.000000              1  \\\n",
       "1           0.516       1  0.310811     0.1  0.334031              1   \n",
       "2           0.304       1  0.324324     0.8  0.636357              3   \n",
       "3           0.698       1  0.283784     0.1  0.000000              2   \n",
       "4           1.000       1  0.337838     0.2  0.500246              1   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9995        0.842       0  0.283784     0.5  0.000000              2   \n",
       "9996        0.332       0  0.229730     1.0  0.228657              1   \n",
       "9997        0.718       1  0.243243     0.7  0.000000              1   \n",
       "9998        0.844       0  0.324324     0.3  0.299226              2   \n",
       "9999        0.884       1  0.135135     0.4  0.518708              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany   \n",
       "0             1               1         0.506735       1              False  \\\n",
       "1             0               1         0.562709       0              False   \n",
       "2             1               0         0.569654       1              False   \n",
       "3             0               0         0.469120       0              False   \n",
       "4             1               1         0.395400       0              False   \n",
       "...         ...             ...              ...     ...                ...   \n",
       "9995          1               0         0.481341       0              False   \n",
       "9996          1               1         0.508490       0              False   \n",
       "9997          0               1         0.210390       1              False   \n",
       "9998          1               0         0.464429       1               True   \n",
       "9999          1               0         0.190914       0              False   \n",
       "\n",
       "      Geography_Spain  \n",
       "0               False  \n",
       "1                True  \n",
       "2               False  \n",
       "3               False  \n",
       "4                True  \n",
       "...               ...  \n",
       "9995            False  \n",
       "9996            False  \n",
       "9997            False  \n",
       "9998            False  \n",
       "9999            False  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cedf3338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      CreditScore  Female       Age  Tenure   Balance  NumOfProducts   \n",
       " 0           0.538       1  0.324324     0.2  0.000000              1  \\\n",
       " 1           0.516       1  0.310811     0.1  0.334031              1   \n",
       " 2           0.304       1  0.324324     0.8  0.636357              3   \n",
       " 3           0.698       1  0.283784     0.1  0.000000              2   \n",
       " 4           1.000       1  0.337838     0.2  0.500246              1   \n",
       " ...           ...     ...       ...     ...       ...            ...   \n",
       " 9995        0.842       0  0.283784     0.5  0.000000              2   \n",
       " 9996        0.332       0  0.229730     1.0  0.228657              1   \n",
       " 9997        0.718       1  0.243243     0.7  0.000000              1   \n",
       " 9998        0.844       0  0.324324     0.3  0.299226              2   \n",
       " 9999        0.884       1  0.135135     0.4  0.518708              1   \n",
       " \n",
       "       HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany   \n",
       " 0             1               1         0.506735              False  \\\n",
       " 1             0               1         0.562709              False   \n",
       " 2             1               0         0.569654              False   \n",
       " 3             0               0         0.469120              False   \n",
       " 4             1               1         0.395400              False   \n",
       " ...         ...             ...              ...                ...   \n",
       " 9995          1               0         0.481341              False   \n",
       " 9996          1               1         0.508490              False   \n",
       " 9997          0               1         0.210390              False   \n",
       " 9998          1               0         0.464429               True   \n",
       " 9999          1               0         0.190914              False   \n",
       " \n",
       "       Geography_Spain  \n",
       " 0               False  \n",
       " 1                True  \n",
       " 2               False  \n",
       " 3               False  \n",
       " 4                True  \n",
       " ...               ...  \n",
       " 9995            False  \n",
       " 9996            False  \n",
       " 9997            False  \n",
       " 9998            False  \n",
       " 9999            False  \n",
       " \n",
       " [10000 rows x 11 columns],\n",
       " 0       1\n",
       " 1       0\n",
       " 2       1\n",
       " 3       0\n",
       " 4       0\n",
       "        ..\n",
       " 9995    0\n",
       " 9996    0\n",
       " 9997    1\n",
       " 9998    1\n",
       " 9999    0\n",
       " Name: Exited, Length: 10000, dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df2.drop([\"Exited\"], axis=1)\n",
    "y = df2[\"Exited\"]\n",
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd533e5f",
   "metadata": {},
   "source": [
    "# *************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22d9bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "619eafe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be1bf5a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8da8d193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          float64\n",
       "Female                 int64\n",
       "Age                  float64\n",
       "Tenure               float64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Geography_Germany       bool\n",
       "Geography_Spain         bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60ec734c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          float64\n",
       "Female                 int64\n",
       "Age                  float64\n",
       "Tenure               float64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Geography_Germany       bool\n",
       "Geography_Spain         bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "725a9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
    "cols=[\"Geography_Germany\", \"Geography_Spain\"]\n",
    "X_train[float_cols] = X_train[float_cols].values.astype(np.float32)\n",
    "X_train[float_cols] = tf.convert_to_tensor(X_train[float_cols], dtype=tf.float32)\n",
    "X_train[cols] = X_train[cols].replace({False:0, True:1})\n",
    "\n",
    "X_test[float_cols] = X_test[float_cols].values.astype(np.float32)\n",
    "X_test[float_cols] = tf.convert_to_tensor(X_test[float_cols], dtype=tf.float32)\n",
    "X_test[cols] = X_test[cols].replace({False:0, True:1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "976285dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(11, input_shape=(11,), activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b5ba87b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.5074 - accuracy: 0.7935\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7993\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8021\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8046\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8100\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8154\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8234\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.8267\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8307\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8326\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8364\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8388\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8401\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8431\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8434\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8451\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8462\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8485\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8506\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8521\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8535\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8553\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8543\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3512 - accuracy: 0.8558\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8553\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8555\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8569\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8586\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8595\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8609\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8611\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8608\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8624\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8620\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8629\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8616\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8633\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8620\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8637\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8621\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8621\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8615\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8626\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8612\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8626\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8612\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8636\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8621\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8634\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8611\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8624\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8621\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8641\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8634\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8620\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8624\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8635\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8597\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8630\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8633\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8619\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8629\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8629\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8627\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8620\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8610\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8629\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8614\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8620\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8626\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8633\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8624\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8627\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8633\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8634\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8630\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8630\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8622\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8626\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8656\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8649\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8618\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8629\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8614\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8627\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8633\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8619\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8637\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8624\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8618\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8615\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8627\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8635\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8611\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8635\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8639\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e670986e30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68bcdacf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3535892367362976, 0.8514999747276306]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f26ea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 871us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02475526],\n",
       "       [0.0460942 ],\n",
       "       [0.08009254],\n",
       "       [0.09215315],\n",
       "       [0.07199851]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a20d365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50bc6e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbf25d2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7054    0\n",
       "442     0\n",
       "3954    0\n",
       "2288    0\n",
       "3196    0\n",
       "6178    0\n",
       "8351    0\n",
       "5658    1\n",
       "2065    0\n",
       "413     1\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "600d1c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      1595\n",
      "           1       0.72      0.43      0.54       405\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.80      0.69      0.73      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4407cf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa2eab",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc30c0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((1509+197)/(1509+197+86+208),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3169a6ea",
   "metadata": {},
   "source": [
    "Precision for 0 class. i.e. Precision for customers who did not exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b09f155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1509/(1509+208),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263a2f6",
   "metadata": {},
   "source": [
    "Precision for 1 class. i.e. Precision for customers who actually churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b423cb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(197/(197+86),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e69285",
   "metadata": {},
   "source": [
    "Recall for 0 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9848000a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1509/(1509+86),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a31c65",
   "metadata": {},
   "source": [
    "Recall for 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf263d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(197/(197+208),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fbf7b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7915\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.8012\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8090\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8100\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.4442 - accuracy: 0.8127\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.8130\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8139\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8150\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8164\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8166\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8158\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4229 - accuracy: 0.8176\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8163\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8161\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8159\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.8156\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8174\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8169\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8179\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8179\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.8190\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8176\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8179\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.8191\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8196\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8211\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.4037 - accuracy: 0.8205\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8225\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8210\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4009 - accuracy: 0.8214\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8246\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8225\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8240\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8253\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1000us/step - loss: 0.3962 - accuracy: 0.8264\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8265\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.8269\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 964us/step - loss: 0.3932 - accuracy: 0.8290\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8304\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 993us/step - loss: 0.3909 - accuracy: 0.8305\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8307\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8316\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8340\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 997us/step - loss: 0.3856 - accuracy: 0.8339\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3854 - accuracy: 0.8361\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 971us/step - loss: 0.3834 - accuracy: 0.8361\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8369\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8364\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8370\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.3795 - accuracy: 0.8394\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8404\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8407\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8413\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 973us/step - loss: 0.3756 - accuracy: 0.8420\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8415\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8428\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8435\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8436\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8457\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8451\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8453\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8456\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8469\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.8469\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8469\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 998us/step - loss: 0.3664 - accuracy: 0.8464\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8482\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8474\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 989us/step - loss: 0.3650 - accuracy: 0.8494\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8490\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8501\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8510\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8490\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8512\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8495\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8518\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8518\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8500\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8521\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8536\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8525\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8533\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8537\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8529\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8536\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8535\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8540\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8560\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8556\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8544\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8559\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8540\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8559\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8565\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8575\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8561\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8561\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8566\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8568\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e676269e40>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(5, input_shape=(11,), activation=\"relu\"),\n",
    "    keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "186d1d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3637291491031647, 0.8475000262260437]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bc2dd6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3535892367362976, 0.8514999747276306]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8ef9f",
   "metadata": {},
   "source": [
    "# 10- Handling imbalanced dataset in machine learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ada6e8",
   "metadata": {},
   "source": [
    "# Method 1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ad5c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb575f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    1595\n",
       "1     405\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7d3992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class0, count_class1 = df2.Exited.value_counts()\n",
    "\n",
    "df_class_0 = df2[df2[\"Exited\"] == 0]\n",
    "df_class_1 = df2[df2[\"Exited\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ea9d687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 12)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "337d27bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 12)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aba6762b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>0.150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704717</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.758911</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691816</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>0.544</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503081</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>0.558</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.447715</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454991</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.323680</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540011</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.605982</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267193</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.546617</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575729</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0.494</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472973</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.352259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346899</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210390</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.299226</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464429</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4074 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Female       Age  Tenure   Balance  NumOfProducts   \n",
       "2646        0.150       1  0.283784     0.5  0.000000              2  \\\n",
       "9944        0.788       0  0.310811     0.7  0.758911              2   \n",
       "5274        0.544       0  0.337838     0.8  0.000000              2   \n",
       "6331        0.558       0  0.229730     0.8  0.447715              1   \n",
       "7873        0.864       0  0.243243     0.5  0.323680              2   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "9981        0.296       0  0.324324     0.3  0.605982              1   \n",
       "9982        0.610       1  0.378378     0.7  0.546617              1   \n",
       "9991        0.494       1  0.472973     0.4  0.352259              1   \n",
       "9997        0.718       1  0.243243     0.7  0.000000              1   \n",
       "9998        0.844       0  0.324324     0.3  0.299226              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany   \n",
       "2646          1               0         0.704717       0              False  \\\n",
       "9944          1               1         0.691816       0               True   \n",
       "5274          1               0         0.503081       0              False   \n",
       "6331          1               1         0.454991       0               True   \n",
       "7873          0               1         0.540011       0              False   \n",
       "...         ...             ...              ...     ...                ...   \n",
       "9981          1               1         0.267193       1               True   \n",
       "9982          1               0         0.575729       1               True   \n",
       "9991          1               0         0.346899       1              False   \n",
       "9997          0               1         0.210390       1              False   \n",
       "9998          1               0         0.464429       1               True   \n",
       "\n",
       "      Geography_Spain  \n",
       "2646             True  \n",
       "9944            False  \n",
       "5274            False  \n",
       "6331            False  \n",
       "7873            False  \n",
       "...               ...  \n",
       "9981            False  \n",
       "9982            False  \n",
       "9991            False  \n",
       "9997            False  \n",
       "9998            False  \n",
       "\n",
       "[4074 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0_under = df_class_0.sample(count_class1)\n",
    "\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "df_test_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69b6ca91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4074"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38ece99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    2037\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_under.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a14e2ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      CreditScore  Female       Age  Tenure   Balance  NumOfProducts   \n",
       " 2646        0.150       1  0.283784     0.5  0.000000              2  \\\n",
       " 9944        0.788       0  0.310811     0.7  0.758911              2   \n",
       " 5274        0.544       0  0.337838     0.8  0.000000              2   \n",
       " 6331        0.558       0  0.229730     0.8  0.447715              1   \n",
       " 7873        0.864       0  0.243243     0.5  0.323680              2   \n",
       " ...           ...     ...       ...     ...       ...            ...   \n",
       " 9981        0.296       0  0.324324     0.3  0.605982              1   \n",
       " 9982        0.610       1  0.378378     0.7  0.546617              1   \n",
       " 9991        0.494       1  0.472973     0.4  0.352259              1   \n",
       " 9997        0.718       1  0.243243     0.7  0.000000              1   \n",
       " 9998        0.844       0  0.324324     0.3  0.299226              2   \n",
       " \n",
       "       HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany   \n",
       " 2646          1               0         0.704717              False  \\\n",
       " 9944          1               1         0.691816               True   \n",
       " 5274          1               0         0.503081              False   \n",
       " 6331          1               1         0.454991               True   \n",
       " 7873          0               1         0.540011              False   \n",
       " ...         ...             ...              ...                ...   \n",
       " 9981          1               1         0.267193               True   \n",
       " 9982          1               0         0.575729               True   \n",
       " 9991          1               0         0.346899              False   \n",
       " 9997          0               1         0.210390              False   \n",
       " 9998          1               0         0.464429               True   \n",
       " \n",
       "       Geography_Spain  \n",
       " 2646             True  \n",
       " 9944            False  \n",
       " 5274            False  \n",
       " 6331            False  \n",
       " 7873            False  \n",
       " ...               ...  \n",
       " 9981            False  \n",
       " 9982            False  \n",
       " 9991            False  \n",
       " 9997            False  \n",
       " 9998            False  \n",
       " \n",
       " [4074 rows x 11 columns],\n",
       " 2646    0\n",
       " 9944    0\n",
       " 5274    0\n",
       " 6331    0\n",
       " 7873    0\n",
       "        ..\n",
       " 9981    1\n",
       " 9982    1\n",
       " 9991    1\n",
       " 9997    1\n",
       " 9998    1\n",
       " Name: Exited, Length: 4074, dtype: int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_test_under.drop([\"Exited\"], axis=1)\n",
    "y = df_test_under[\"Exited\"]\n",
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab31479",
   "metadata": {},
   "source": [
    "### stratify will equal 0 and 1 for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe65fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b605c55f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    1630\n",
       "0    1629\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5ee6640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          float64\n",
       "Female                 int64\n",
       "Age                  float64\n",
       "Tenure               float64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Geography_Germany       bool\n",
       "Geography_Spain         bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0701a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
    "cols=[\"Geography_Germany\", \"Geography_Spain\"]\n",
    "X_train[float_cols] = X_train[float_cols].values.astype(np.float32)\n",
    "X_train[float_cols] = tf.convert_to_tensor(X_train[float_cols], dtype=tf.float32)\n",
    "X_train[cols] = X_train[cols].replace({False:0, True:1})\n",
    "\n",
    "X_test[float_cols] = X_test[float_cols].values.astype(np.float32)\n",
    "X_test[float_cols] = tf.convert_to_tensor(X_test[float_cols], dtype=tf.float32)\n",
    "X_test[cols] = X_test[cols].replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8dc99e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          float32\n",
       "Female                 int64\n",
       "Age                  float32\n",
       "Tenure               float32\n",
       "Balance              float32\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float32\n",
       "Geography_Germany      int64\n",
       "Geography_Spain        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c18450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(11, input_dim=11, activation='relu'),\n",
    "        keras.layers.Dense(4, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43b34ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5443\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.6109\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6444\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6582\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6582\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.6523\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6191 - accuracy: 0.6609\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.6634\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6720\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.6717\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6717\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6763\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.6806\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5961 - accuracy: 0.6852\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5930 - accuracy: 0.6867\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.6910\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.6919\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6910\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.6941\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6968\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6935\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.7039\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.7005\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7067\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.7076\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7091\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7119\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7183\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.7217\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7156\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7208\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5509 - accuracy: 0.7275\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.7245\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7269\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7306\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7330\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7361\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7361\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7392\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7410\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7404\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7380\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7456\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7450\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7441\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7465\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7490\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7438\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.7478\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7475\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7490\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7493\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7499\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7499\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7524\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7481\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7518\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7527\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7548\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7564\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7533\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7545\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7570\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7518\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7539\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7564\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7554\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7570\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7548\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7570\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7564\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7600\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7582\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7585\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7518\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7567\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7554\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7567\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7597\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7604\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7591\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7613\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7588\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7604\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7567\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7594\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7622\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7579\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7564\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7604\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7564\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7634\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7600\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7622\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7597\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7613\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7665\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7597\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7613\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7625\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7963\n",
      "[0.45380699634552, 0.7963190078735352]\n",
      "26/26 [==============================] - 0s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       408\n",
      "           1       0.81      0.77      0.79       407\n",
      "\n",
      "    accuracy                           0.80       815\n",
      "   macro avg       0.80      0.80      0.80       815\n",
      "weighted avg       0.80      0.80      0.80       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train,y_train,X_test,y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a718f9",
   "metadata": {},
   "source": [
    "# Method2: Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c822b733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class0, count_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49388f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>0.396</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.465350</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.792944</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>0.564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.504391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888250</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.476905</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742074</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>0.804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221641</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>0.564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.533260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.172994</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777052</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.527718</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180419</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>0.710</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.570948</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.442126</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>0.708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.532714</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725368</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>0.860</td>\n",
       "      <td>1</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.379422</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631554</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Female       Age  Tenure   Balance  NumOfProducts   \n",
       "3146        0.396       1  0.135135     0.8  0.465350              2  \\\n",
       "2236        0.564       0  0.310811     0.3  0.504391              1   \n",
       "9494        0.878       0  0.337838     0.8  0.476905              2   \n",
       "4834        0.804       1  0.229730     0.2  0.000000              1   \n",
       "3303        0.564       1  0.351351     0.3  0.533260              1   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "3245        0.328       1  0.364865     0.3  0.434568              1   \n",
       "1505        0.512       0  0.405405     0.4  0.527718              1   \n",
       "2168        0.710       1  0.513514     0.2  0.570948              1   \n",
       "1657        0.708       1  0.486486     0.6  0.532714              3   \n",
       "5243        0.860       1  0.256757     1.0  0.379422              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany   \n",
       "3146          1               1         0.792944       1              False  \\\n",
       "2236          0               0         0.888250       1               True   \n",
       "9494          0               1         0.742074       1               True   \n",
       "4834          1               0         0.221641       1              False   \n",
       "3303          1               1         0.172994       1              False   \n",
       "...         ...             ...              ...     ...                ...   \n",
       "3245          0               1         0.777052       1               True   \n",
       "1505          0               0         0.180419       1               True   \n",
       "2168          1               0         0.442126       1               True   \n",
       "1657          1               0         0.725368       1               True   \n",
       "5243          1               0         0.631554       1               True   \n",
       "\n",
       "      Geography_Spain  \n",
       "3146            False  \n",
       "2236            False  \n",
       "9494            False  \n",
       "4834             True  \n",
       "3303            False  \n",
       "...               ...  \n",
       "3245            False  \n",
       "1505            False  \n",
       "2168            False  \n",
       "1657            False  \n",
       "5243            False  \n",
       "\n",
       "[7963 rows x 12 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1_over = df_class_1.sample(count_class0, replace=True)\n",
    "df_class_1_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a2fbb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Female</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050261</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.566170</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374680</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.434568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777052</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.527718</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.180419</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>0.710</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.570948</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.442126</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>0.708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.532714</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725368</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>0.860</td>\n",
       "      <td>1</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.379422</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631554</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15926 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Female       Age  Tenure   Balance  NumOfProducts   \n",
       "1           0.516       1  0.310811     0.1  0.334031              1  \\\n",
       "3           0.698       1  0.283784     0.1  0.000000              2   \n",
       "4           1.000       1  0.337838     0.2  0.500246              1   \n",
       "6           0.944       0  0.432432     0.7  0.000000              2   \n",
       "8           0.302       0  0.351351     0.4  0.566170              2   \n",
       "...           ...     ...       ...     ...       ...            ...   \n",
       "3245        0.328       1  0.364865     0.3  0.434568              1   \n",
       "1505        0.512       0  0.405405     0.4  0.527718              1   \n",
       "2168        0.710       1  0.513514     0.2  0.570948              1   \n",
       "1657        0.708       1  0.486486     0.6  0.532714              3   \n",
       "5243        0.860       1  0.256757     1.0  0.379422              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany   \n",
       "1             0               1         0.562709       0              False  \\\n",
       "3             0               0         0.469120       0              False   \n",
       "4             1               1         0.395400       0              False   \n",
       "6             1               1         0.050261       0              False   \n",
       "8             0               1         0.374680       0              False   \n",
       "...         ...             ...              ...     ...                ...   \n",
       "3245          0               1         0.777052       1               True   \n",
       "1505          0               0         0.180419       1               True   \n",
       "2168          1               0         0.442126       1               True   \n",
       "1657          1               0         0.725368       1               True   \n",
       "5243          1               0         0.631554       1               True   \n",
       "\n",
       "      Geography_Spain  \n",
       "1                True  \n",
       "3               False  \n",
       "4                True  \n",
       "6               False  \n",
       "8               False  \n",
       "...               ...  \n",
       "3245            False  \n",
       "1505            False  \n",
       "2168            False  \n",
       "1657            False  \n",
       "5243            False  \n",
       "\n",
       "[15926 rows x 12 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "df_test_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0840c3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15926"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class0*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "96061440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_over.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b798d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_over.drop([\"Exited\"], axis=1)\n",
    "y = df_test_over[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2cd7298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "517ca162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Exited\n",
       " 1    6370\n",
       " 0    6370\n",
       " Name: count, dtype: int64,\n",
       " Exited\n",
       " 0    1593\n",
       " 1    1593\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc0562d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
    "cols=[\"Geography_Germany\", \"Geography_Spain\"]\n",
    "X_train[float_cols] = X_train[float_cols].values.astype(np.float32)\n",
    "X_train[float_cols] = tf.convert_to_tensor(X_train[float_cols], dtype=tf.float32)\n",
    "X_train[cols] = X_train[cols].replace({False:0, True:1})\n",
    "\n",
    "X_test[float_cols] = X_test[float_cols].values.astype(np.float32)\n",
    "X_test[float_cols] = tf.convert_to_tensor(X_test[float_cols], dtype=tf.float32)\n",
    "X_test[cols] = X_test[cols].replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42498eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.6619 - accuracy: 0.6246\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6574\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.6867\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5837 - accuracy: 0.7043\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5628 - accuracy: 0.7182\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5535 - accuracy: 0.7264\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7359\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.7427\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.7486\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7574\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7601\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7596\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7602\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7638\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7639\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7654\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7656\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7655\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7687\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7677\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7701\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7677\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7692\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4736 - accuracy: 0.7688\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4718 - accuracy: 0.7691\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.7704\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7741\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.7727\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4689 - accuracy: 0.7722\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7717\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7756\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4669 - accuracy: 0.7743\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4660 - accuracy: 0.7749\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4649 - accuracy: 0.7753\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7745\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7757\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7746\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4644 - accuracy: 0.7753\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7768\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7778\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7770\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7777\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4622 - accuracy: 0.7768\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4607 - accuracy: 0.7778\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4615 - accuracy: 0.7778\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7792\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7782\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4594 - accuracy: 0.7800\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7799\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7800\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7813\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4591 - accuracy: 0.7794\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4582 - accuracy: 0.7794\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4579 - accuracy: 0.7786\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7805\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4567 - accuracy: 0.7775\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7830\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7816\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7796\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7781\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7818\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7812\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7767\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7819\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7804\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7816\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7811\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7803\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7812\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7807\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7797\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7828\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7817\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7830\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4518 - accuracy: 0.7822\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7816\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.7816\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4509 - accuracy: 0.7830\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7849\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.7816\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4518 - accuracy: 0.7836\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4516 - accuracy: 0.7825\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4509 - accuracy: 0.7820\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7838\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7841\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4508 - accuracy: 0.7839\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7821\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7827\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.7821\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4512 - accuracy: 0.7831\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4491 - accuracy: 0.7819\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7819\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7813\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7834\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7830\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7830\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7814\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7842\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7841\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7834\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7765\n",
      "[0.46014079451560974, 0.7765222787857056]\n",
      "100/100 [==============================] - 0s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.77      1593\n",
      "           1       0.76      0.82      0.79      1593\n",
      "\n",
      "    accuracy                           0.78      3186\n",
      "   macro avg       0.78      0.78      0.78      3186\n",
      "weighted avg       0.78      0.78      0.78      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train,y_train,X_test,y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2122e",
   "metadata": {},
   "source": [
    "# Method3: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d3844ae",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/a3/9e/fbe60a768502af54563dcb59ca7856f5a8833b3ad5ada658922e1ab09b7f/imbalanced_learn-0.11.0-py3-none-any.whl.metadata\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\emirk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\emirk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\emirk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\emirk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\emirk\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn) (3.1.0)\n",
      "Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "   ---------------------------------------- 0.0/235.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/235.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/235.6 kB ? eta -:--:--\n",
      "   ------------------ ------------------- 112.6/235.6 kB 726.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/235.6 kB 722.1 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 174.1/235.6 kB 697.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 204.8/235.6 kB 692.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  235.5/235.6 kB 686.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 235.6/235.6 kB 687.2 kB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04b550ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop([\"Exited\"], axis=1)\n",
    "y = df2[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5818e3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b7bef215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "1    7963\n",
       "0    7963\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=\"minority\")\n",
    "X_sm, y_sm = smote.fit_resample(X,y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9470ab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm,y_sm,test_size=0.2,random_state=0, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad2d5656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Exited\n",
       " 1    6370\n",
       " 0    6370\n",
       " Name: count, dtype: int64,\n",
       " Exited\n",
       " 0    1593\n",
       " 1    1593\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(), y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4de36372",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
    "cols=[\"Geography_Germany\", \"Geography_Spain\"]\n",
    "X_train[float_cols] = X_train[float_cols].values.astype(np.float32)\n",
    "X_train[float_cols] = tf.convert_to_tensor(X_train[float_cols], dtype=tf.float32)\n",
    "X_train[cols] = X_train[cols].replace({False:0, True:1})\n",
    "\n",
    "X_test[float_cols] = X_test[float_cols].values.astype(np.float32)\n",
    "X_test[float_cols] = tf.convert_to_tensor(X_test[float_cols], dtype=tf.float32)\n",
    "X_test[cols] = X_test[cols].replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b461b760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.6783 - accuracy: 0.5989\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.6412 - accuracy: 0.6557\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6983\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.7232\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5531 - accuracy: 0.7363\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7433\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.5257 - accuracy: 0.7531\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7553\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7599\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7623\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4957 - accuracy: 0.7658\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.7688\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7671\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4817 - accuracy: 0.7711\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4784 - accuracy: 0.7719\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7728\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7740\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4698 - accuracy: 0.7746\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4667 - accuracy: 0.7769\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4658 - accuracy: 0.7743\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4633 - accuracy: 0.7768\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7782\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7787\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7830\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7823\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7813\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7818\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7812\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7818\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7834\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7822\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7829\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7853\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7858\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7850\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4468 - accuracy: 0.7852\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7867\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7845\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7873\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7867\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7881\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4438 - accuracy: 0.7878\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4432 - accuracy: 0.7880\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4429 - accuracy: 0.7881\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7879\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7892\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4405 - accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.7873\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4403 - accuracy: 0.7892\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7906\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4399 - accuracy: 0.7883\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4407 - accuracy: 0.7894\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7892\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7901\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7915\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7900\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7911\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7940\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4380 - accuracy: 0.7874\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4379 - accuracy: 0.7910\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4378 - accuracy: 0.7906\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7908\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4365 - accuracy: 0.7908\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7899\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4358 - accuracy: 0.7902\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4353 - accuracy: 0.7902\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4358 - accuracy: 0.7911\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4354 - accuracy: 0.7946\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7920\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7962\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7926\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.7928\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4341 - accuracy: 0.7940\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7944\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.7928\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7935\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7944\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7926\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7936\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4322 - accuracy: 0.7922\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4324 - accuracy: 0.7927\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4320 - accuracy: 0.7927\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7951\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.7946\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4315 - accuracy: 0.7943\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7940\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.7947\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7957\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7947\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7958\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.7951\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4314 - accuracy: 0.7947\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4300 - accuracy: 0.7956\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4306 - accuracy: 0.7933\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.7938\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7966\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7958\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4291 - accuracy: 0.7984\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.4301 - accuracy: 0.7911\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7974\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7863\n",
      "[0.4406868815422058, 0.7862523794174194]\n",
      "100/100 [==============================] - 0s 937us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1593\n",
      "           1       0.79      0.77      0.78      1593\n",
      "\n",
      "    accuracy                           0.79      3186\n",
      "   macro avg       0.79      0.79      0.79      3186\n",
      "weighted avg       0.79      0.79      0.79      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train,y_train,X_test,y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a6a103",
   "metadata": {},
   "source": [
    "# Method4: Use of Ensemble with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7ea7e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop([\"Exited\"], axis=1)\n",
    "y = df2[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3173d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "53c0f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
    "cols=[\"Geography_Germany\", \"Geography_Spain\"]\n",
    "X_train[float_cols] = X_train[float_cols].values.astype(np.float32)\n",
    "X_train[float_cols] = tf.convert_to_tensor(X_train[float_cols], dtype=tf.float32)\n",
    "X_train[cols] = X_train[cols].replace({False:0, True:1})\n",
    "\n",
    "X_test[float_cols] = X_test[float_cols].values.astype(np.float32)\n",
    "X_test[float_cols] = tf.convert_to_tensor(X_test[float_cols], dtype=tf.float32)\n",
    "X_test[cols] = X_test[cols].replace({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "54cd6c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "895a1580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9079754601226995"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6370/1630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7c237f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = X_train.copy()\n",
    "df3['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "699db8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_class0 = df3[df3.Exited==0]\n",
    "df3_class1 = df3[df3.Exited==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0b2da9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train.Exited\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4c0baa14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 0.6783 - accuracy: 0.5865\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6433\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6528\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6549\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6663\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.6733\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6798\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.6816\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.6908\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.6948\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.7031\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5730 - accuracy: 0.7025\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7031\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7061\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7141\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5570 - accuracy: 0.7166\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5531 - accuracy: 0.7224\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7270\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5465 - accuracy: 0.7239\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7279\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 0.7294\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7331\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7331\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7362\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5312 - accuracy: 0.7390\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7365\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7408\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5257 - accuracy: 0.7442\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7463\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7472\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7503\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7485\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7503\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7515\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.7571\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7577\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7540\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5074 - accuracy: 0.7580\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7564\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7558\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7641\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.7607\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7607\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7650\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7641\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7629\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4952 - accuracy: 0.7613\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7675\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7666\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7650\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7699\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7672\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7684\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7650\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7656\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7675\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7690\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7653\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7709\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7669\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7706\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7690\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7721\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7733\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7693\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7678\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7709\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7706\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7681\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7715\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7752\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7709\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7709\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7675\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7739\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7758\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7745\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7782\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7718\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7739\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7748\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7773\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7739\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7742\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7752\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7776\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7770\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7755\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7742\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7791\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7755\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7773\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7779\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7794\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7831\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7782\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7764\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7816\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7788\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7801\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7705\n",
      "[0.4830549955368042, 0.7705000042915344]\n",
      "63/63 [==============================] - 0s 886us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84      1593\n",
      "           1       0.46      0.75      0.57       407\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.69      0.76      0.71      2000\n",
      "weighted avg       0.83      0.77      0.79      2000\n",
      "\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 0.6899 - accuracy: 0.5362\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6319\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6506\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6632\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6136 - accuracy: 0.6690\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6883\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6939\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.7015\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5795 - accuracy: 0.7034\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.7092\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7156\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7172\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7172\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.7196\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7175\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5492 - accuracy: 0.7267\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5458 - accuracy: 0.7310\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7307\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7359\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7374\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7399\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.7396\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7393\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.7387\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7393\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7454\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.7469\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7460\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7491\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7497\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7482\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7540\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.7469\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7509\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7567\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7574\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7586\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.7617\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7574\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7592\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7607\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7620\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7564\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7601\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7644\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.7626\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7620\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7626\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7632\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7650\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7656\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7656\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7663\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7653\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7644\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7650\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7647\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7699\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.7702\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7687\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7693\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7706\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7709\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7702\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7696\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7663\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7702\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7675\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7727\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7672\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7739\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7724\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7715\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7739\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7739\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7736\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7742\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7724\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7752\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7696\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7748\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7752\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7739\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7761\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7782\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7767\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7752\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7770\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7804\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7798\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7770\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7779\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7764\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7767\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7767\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7782\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7730\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7782\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7776\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7721\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7840\n",
      "[0.44851329922676086, 0.7839999794960022]\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86      1593\n",
      "           1       0.48      0.67      0.56       407\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.69      0.74      0.71      2000\n",
      "weighted avg       0.82      0.78      0.80      2000\n",
      "\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 1ms/step - loss: 0.6948 - accuracy: 0.5129\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5736\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.6132\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6368\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6641\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.6724\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.6844\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6893\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6070 - accuracy: 0.6982\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.7040\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7064\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5896 - accuracy: 0.7064\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.7123\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7178\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7245\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7255\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.7285\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7301\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7350\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.7359\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7399\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7454\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7454\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7469\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7525\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5289 - accuracy: 0.7537\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7564\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.7549\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7604\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7580\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7617\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7589\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.7580\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7635\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7626\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7595\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7638\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7620\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7644\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7623\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7678\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7647\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7669\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7663\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7663\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7647\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7656\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7675\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7607\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7696\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7678\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7669\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7656\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7690\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7690\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7702\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7675\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7666\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7660\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7678\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7678\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7690\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7687\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7687\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7721\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7702\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7696\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7709\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7712\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7681\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7712\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7736\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7712\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7709\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7758\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7696\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7718\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7699\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7712\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7715\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7730\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7693\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7690\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7706\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7709\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7690\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7742\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7699\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7715\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7727\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7712\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7718\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7730\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7690\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7709\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7724\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7721\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7724\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7702\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7736\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7610\n",
      "[0.4990887939929962, 0.7609999775886536]\n",
      "63/63 [==============================] - 0s 988us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      1593\n",
      "           1       0.45      0.76      0.57       407\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.69      0.76      0.70      2000\n",
      "weighted avg       0.83      0.76      0.78      2000\n",
      "\n",
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 2ms/step - loss: 0.6743 - accuracy: 0.5704\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6225\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6386\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.6460\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.6617\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6711\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.6875\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6920\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6887\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7061\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7080\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7074\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7141\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7209\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7164\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.7293\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7280\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7334\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7305\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7360\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7392\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7392\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7428\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7424\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.7453\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7450\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7498\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7531\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7495\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7534\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7569\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7540\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7556\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7569\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7563\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7601\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7563\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7582\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7592\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7595\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7524\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7605\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.7579\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7598\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7646\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7611\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7588\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7598\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7643\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7611\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7576\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7617\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7608\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7624\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7582\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7627\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7601\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7614\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7605\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7605\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7621\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7621\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7601\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7621\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7643\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7601\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7650\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7633\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7630\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7678\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7559\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7637\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7640\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7630\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7640\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7659\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7650\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7611\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7691\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7608\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7614\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7627\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7653\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7643\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7621\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7637\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7624\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7640\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7666\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7669\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7621\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7659\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7646\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7656\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7666\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7627\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7633\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7678\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7675\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.7405\n",
      "[0.5309635996818542, 0.7404999732971191]\n",
      "63/63 [==============================] - 0s 928us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.82      1593\n",
      "           1       0.43      0.79      0.55       407\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.68      0.76      0.69      2000\n",
      "weighted avg       0.83      0.74      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr = [[0,1630],[1630,3260],[3260,4890],[4890,6370]]\n",
    "predictions = []\n",
    "for i in arr:\n",
    "    X_train, y_train = get_train_batch(df3_class0, df3_class1, i[0], i[1])\n",
    "    \n",
    "    X_train[float_cols] = X_train[float_cols].values.astype(np.float32)\n",
    "    X_train[float_cols] = tf.convert_to_tensor(X_train[float_cols], dtype=tf.float32)\n",
    "    X_train[cols] = X_train[cols].replace({False:0, True:1})\n",
    "    y_pred = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)\n",
    "    predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8d879f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = np.zeros(len(predictions[0]))\n",
    "\n",
    "for i in range(len(predictions[0])):\n",
    "    n_ones = sum(pred[i] for pred in predictions)  # Her bir modele göre 1'lerin sayısını hesaplayın\n",
    "    if n_ones > len(predictions) / 2:  # Eğer 1'lerin sayısı çoğunluğu oluşturuyorsa\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "19ec914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85      1593\n",
      "           1       0.48      0.71      0.57       407\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.70      0.75      0.71      2000\n",
      "weighted avg       0.83      0.78      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "00ae817d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1630, 3260, 6370]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_samples = 6370\n",
    "minority_class_samples = 1630\n",
    "\n",
    "# Bölme sayısını belirleyin\n",
    "num_splits = total_samples // minority_class_samples\n",
    "\n",
    "# Bölmeleri hesaplayın\n",
    "breakpoints = [i * minority_class_samples for i in range(num_splits)] + [total_samples]\n",
    "breakpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e7ba5211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[slice(0, 1630, None), slice(1630, 3260, None), slice(3260, 6370, None)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices = [slice(breakpoints[i], breakpoints[i + 1]) for i in range(len(breakpoints) - 1)]\n",
    "slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7c6bcd6d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6546    0\n",
       " 9599    0\n",
       " 8084    0\n",
       " 9841    0\n",
       " 1165    0\n",
       "        ..\n",
       " 16      1\n",
       " 3138    1\n",
       " 9882    1\n",
       " 6380    1\n",
       " 9156    1\n",
       " Name: Exited, Length: 1630, dtype: int64,\n",
       " 6864    1\n",
       " 8334    1\n",
       " 5632    1\n",
       " 3637    1\n",
       " 7729    1\n",
       "        ..\n",
       " 8674    1\n",
       " 8153    1\n",
       " 1621    1\n",
       " 6727    1\n",
       " 6399    1\n",
       " Name: Exited, Length: 1480, dtype: int64,\n",
       " Series([], Name: Exited, dtype: int64)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data = [y_train[s] for s in slices]\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4095ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
